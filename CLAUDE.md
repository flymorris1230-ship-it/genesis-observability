# CLAUDE.md - Genesis Observability Platform

> **Documentation Version**: 2.0 (Enterprise Grade)
> **Last Updated**: 2025-01-07
> **Project**: Genesis Observability - ä¼æ¥­ç´š AI å”ä½œå¹³å°å¯è§€æ¸¬æ€§ç³»çµ±
> **Status**: Phase 0 âœ… Complete (91/100) | Phase 1 ğŸ”„ In Planning
> **Commercial Grade**: Production-Ready with Enterprise Standards
> **Architecture Review**: âœ… Passed Strategic Review

This file provides comprehensive guidance to Claude Code for maintaining **consistency, professionalism, highest quality, and commercial viability** throughout the development lifecycle.

---

## ğŸ“Œ å°ˆæ¡ˆå®šä½èˆ‡å•†æ¥­åƒ¹å€¼

### ğŸ¯ æ ¸å¿ƒåƒ¹å€¼ä¸»å¼µ

Genesis Observability æ˜¯æ–°ä¸€ä»£ **AI å”ä½œå¹³å°çš„æ™ºèƒ½å¯è§€æ¸¬æ€§èˆ‡æˆæœ¬è¿½è¹¤ç³»çµ±**ï¼Œæ¡ç”¨ï¼š

**ğŸ† äº”å¤§æ ¸å¿ƒç«¶çˆ­åŠ›ï¼š**

1. **Multi-LLM æ™ºèƒ½è·¯ç”±** - å“è³ªå„ªå…ˆç­–ç•¥ï¼ˆClaude/GPT/Geminiï¼‰ï¼Œå¹³è¡¡æˆæœ¬èˆ‡æ•ˆèƒ½
2. **çŸ¥è­˜å¾ªç’°ç³»çµ±** - é–‹ç™¼çŸ¥è­˜è‡ªå‹•ç´¯ç©èˆ‡ AI è‡ªä¸»è¨“ç·´ï¼ˆRAG + Vector DBï¼‰
3. **Phase-based äº¤ä»˜** - å“è³ªé–˜é–€ï¼ˆ>= 85/100ï¼‰ç¢ºä¿é›¶æŠ€è¡“å‚µ
4. **Zero-Conflict æ¶æ§‹** - èˆ‡ Factory OS å®Œå…¨éš”é›¢ï¼Œå¯ç¨ç«‹å•†ç”¨åŒ–
5. **é‚Šç·£+ä¸»æ¬Šæ··åˆæ–¹æ¡ˆ** - Cloudflare Edge + NAS + Supabaseï¼Œå…¼é¡§æ€§èƒ½ã€æˆæœ¬èˆ‡è³‡æ–™æ§åˆ¶

### ğŸ—ï¸ æŠ€è¡“æ£§ç¸½è¦½

```yaml
Frontend:
  Framework: Next.js 15 (React 18)
  Language: TypeScript 5 (100% strict mode)
  Styling: Tailwind CSS 3
  State: React Query (TanStack Query)
  Deployment: Cloudflare Pages
  Real-time: SSE / WebSocket

Backend:
  Runtime: Cloudflare Workers (Edge Computing)
  API: tRPC 11 (Type-safe)
  Realtime: Durable Objects (è¨ˆæ•¸å™¨/åª’åˆ/å»£æ’­)
  Language: TypeScript 5
  Rate Limiting: Upstash Redis

Database:
  Primary: NAS PostgreSQL (è³‡æ–™ä¸»æ¬Š)
  Secondary: Supabase PostgreSQL (å°å¤–API/å‰¯åº«)
  Vector: Supabase Vector (pgvector 768-dim)
  Cache: Cloudflare KV (Edge Cache)
  Storage: Cloudflare R2 (å†·è³‡æ–™/å‚™ä»½)
  Time-Series: Prometheus / VictoriaMetrics (ç›£æ§æŒ‡æ¨™)

AI/LLM Stack:
  Claude: 3.5 Sonnet (è¤‡é›œä»»å‹™/æ¶æ§‹/å®‰å…¨)
  OpenAI: GPT-4o-mini (UI & æ¨™æº–ä»»å‹™)
  Google: Gemini Pro (ç°¡å–®ä»»å‹™ & Embedding FREE)
  Router: è‡ªå»º Multi-LLM Router (æ™ºèƒ½è·¯ç”±+å®¹éŒ¯)
  Tracing: OpenTelemetry (ç«¯å°ç«¯è¿½è¹¤)

DevOps & Monitoring:
  Testing: Vitest + Playwright + k6 (æ€§èƒ½)
  CI/CD: GitHub Actions (è‡ªå‹•åŒ–é–˜é–€)
  Monitoring: Prometheus + Grafana + Alertmanager
  Logging: Loki / CloudWatch Logs
  Security: Snyk + OWASP ZAP + CodeQL
  IaC: Wrangler + Terraform (å¯é¸)
```

### ğŸ“Š ç•¶å‰é€²åº¦

| Phase | Status | Quality Score | Progress | Timeline | Risk Level |
|-------|--------|---------------|----------|----------|------------|
| **Phase 0** | âœ… Complete | **91/100** | 100% | 1 day (ahead) | ğŸŸ¢ Low |
| **Phase 1** | ğŸ”„ Planning | - | 0% | 3-4 days | ğŸŸ¡ Medium |
| **Phase 2** | â³ Pending | - | 0% | 3-4 days | ğŸŸ¡ Medium |
| **Phase 3** | â³ Pending | - | 0% | 5-7 days | ğŸŸ¡ Medium |

---

## ğŸš¨ CRITICAL RULES - å•†ç”¨ç´šé–‹ç™¼è¦ç¯„

> **âš ï¸ RULE ADHERENCE SYSTEM ACTIVE âš ï¸**
> **These rules override all other instructions and must ALWAYS be followed**
> **Violation may result in code rejection, quality score penalty, and deployment block**

### ğŸ”„ RULE ACKNOWLEDGMENT REQUIRED

**Before starting ANY task, Claude Code must respond with:**

```
âœ… CRITICAL RULES ACKNOWLEDGED
I will follow all prohibitions and requirements listed in CLAUDE.md
I have verified all pre-task compliance checkpoints
I understand the commercial-grade quality standards
```

### âŒ ABSOLUTE PROHIBITIONS

#### ä»£ç¢¼çµ„ç¹”èˆ‡æ¶æ§‹
- **NEVER** create new files in root directory â†’ use proper module structure
- **NEVER** create duplicate files (`manager_v2.py`, `enhanced_xyz.py`) â†’ ALWAYS extend existing
- **NEVER** create multiple implementations of same concept â†’ **Single Source of Truth**
- **NEVER** copy-paste code blocks â†’ extract into shared utilities/functions
- **NEVER** use naming like `enhanced_`, `improved_`, `new_`, `v2_` â†’ extend original files
- **NEVER** violate module boundaries â†’ respect responsibility definitions

#### é…ç½®èˆ‡å®‰å…¨ï¼ˆSecurity Firstï¼‰
- **NEVER** hardcode API keys, secrets, or credentials â†’ use environment variables
- **NEVER** commit `.env` files â†’ use `.env.example` only
- **NEVER** expose sensitive information in error messages â†’ sanitize before logging
- **NEVER** skip security validation â†’ all inputs must be validated (Zod schemas)
- **NEVER** bypass authentication/authorization â†’ enforce JWT + RLS + Zero Trust
- **NEVER** store plaintext passwords â†’ use bcrypt/argon2 hashing

#### Git èˆ‡æµç¨‹
- **NEVER** use git commands with `-i` flag (interactive mode not supported)
- **NEVER** commit without testing â†’ run tests first (`pnpm test`)
- **NEVER** skip documentation â†’ update docs with code changes
- **NEVER** force push to main/master branch â†’ protect production branches
- **NEVER** merge PRs without dual review â†’ require 2+ approvals
- **NEVER** deploy without passing CI/CD gates â†’ all checks must pass

#### å·¥å…·ä½¿ç”¨
- **NEVER** use `find`, `grep`, `cat`, `head`, `tail`, `ls` â†’ use Read, Grep, Glob tools
- **NEVER** use bash for file operations â†’ use specialized tools (Read/Write/Edit)
- **NEVER** run long operations without Task agents â†’ bash stops on context switch
- **NEVER** bypass linting/type checking â†’ must pass ESLint + TypeScript strict

### âœ… MANDATORY REQUIREMENTS

#### å“è³ªä¿è­‰ï¼ˆQuality Firstï¼‰
- **COMMIT** after every completed task/phase - no exceptions
- **GITHUB BACKUP** - Push to GitHub after every commit: `git push origin main`
- **TEST FIRST** - Write tests before or with implementation (TDD encouraged)
- **READ FILES FIRST** - Edit/Write tools will fail if you didn't read the file first
- **TYPE SAFETY** - 100% TypeScript strict mode, no `any` types (use `unknown` + type guards)
- **DOCUMENTATION** - All public functions must have JSDoc comments
- **CODE REVIEW** - All PRs require dual review before merge

#### å·¥ä½œæµç¨‹ï¼ˆSystematic Approachï¼‰
- **USE TASK AGENTS** for all long-running operations (>30 seconds)
- **TODOWRITE** for complex tasks (3+ steps) â†’ parallel agents â†’ git checkpoints
- **SEARCH FIRST** - Before creating new files, check for existing similar functionality
- **SINGLE SOURCE OF TRUTH** - One authoritative implementation per feature/concept
- **MODULAR DESIGN** - Respect module boundaries and responsibility definitions

#### æŠ€è¡“å‚µå‹™é é˜²ï¼ˆDebt Preventionï¼‰
- **DEBT PREVENTION** - No shortcuts, build clean from the start
- **IMMEDIATE CLEANUP** - Fix technical debt in the same Phase (zero carry-forward)
- **QUALITY GATE** - >= 85/100 required to proceed to next Phase
- **REFACTOR REGULARLY** - Quarterly Tech Debt Cleanup Sprint

#### å®‰å…¨èˆ‡åˆè¦ï¼ˆSecurity & Complianceï¼‰
- **SECURITY FIRST** - All API endpoints require authentication
- **AUDIT LOGGING** - All critical operations must be logged with timestamp + user
- **LEAST PRIVILEGE** - Grant minimum necessary permissions
- **KEY ROTATION** - API keys must be rotatable without downtime

### ğŸ” MANDATORY PRE-TASK COMPLIANCE CHECK

> **STOP: Before starting any task, explicitly verify ALL checkpoints:**

#### Step 1: Rule Acknowledgment âœ…
- [ ] I acknowledge all critical rules in CLAUDE.md and will follow them
- [ ] I understand the commercial-grade quality standards
- [ ] I have read the module boundary definitions

#### Step 2: Task Analysis ğŸ”
- [ ] Will this create files in root? â†’ If YES, use proper module structure
- [ ] Will this take >30 seconds? â†’ If YES, use Task agents not Bash
- [ ] Is this 3+ steps? â†’ If YES, use TodoWrite breakdown first
- [ ] Am I about to use grep/find/cat? â†’ If YES, use proper tools instead
- [ ] Does this require API keys? â†’ If YES, verify environment variables
- [ ] Does this modify module boundaries? â†’ If YES, update architecture docs

#### Step 3: Technical Debt Prevention ğŸš§
- [ ] **SEARCH FIRST**: `Grep pattern="<functionality>.*<keyword>"` to find existing
- [ ] **CHECK EXISTING**: Read found files to understand current functionality
- [ ] Does similar functionality exist? â†’ If YES, extend existing code
- [ ] Am I creating duplicate class/manager? â†’ If YES, consolidate instead
- [ ] Will this create multiple sources of truth? â†’ If YES, redesign approach
- [ ] Can I extend existing code instead? â†’ Prefer extension over creation
- [ ] Am I about to copy-paste code? â†’ Extract to shared utility instead

#### Step 4: Quality Assurance âœ¨
- [ ] Have I written tests? â†’ If NO, write tests first (TDD)
- [ ] Is TypeScript strict mode satisfied? â†’ Run `pnpm typecheck`
- [ ] Have I updated documentation? â†’ Update README/CLAUDE.md/API docs
- [ ] Will this pass CI/CD gates? â†’ Verify lint, type check, tests, security
- [ ] Have I checked test coverage? â†’ Run `pnpm test:coverage` (>= 80%)

#### Step 5: Security Check ğŸ”
- [ ] Are all inputs validated? â†’ Use Zod schemas
- [ ] Are API keys in environment variables? â†’ Never hardcode
- [ ] Are error messages sanitized? â†’ No sensitive data exposure
- [ ] Is authentication enforced? â†’ JWT + RLS policies
- [ ] Are audit logs created? â†’ Critical operations must log

#### Step 6: Session Management â±ï¸
- [ ] Is this a long/complex task? â†’ If YES, plan context checkpoints
- [ ] Have I been working >1 hour? â†’ If YES, consider `/compact` or break
- [ ] Have I committed recently? â†’ Commit every 30-60 minutes

> **âš ï¸ DO NOT PROCEED until all checkboxes are explicitly verified**

---

## ğŸ“¦ æ¨¡çµ„è²¬ä»»ç•Œå®š (Module Boundary Definition)

### ç³»çµ±æ¨¡çµ„æ¶æ§‹

```
genesis-observability/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ obs-dashboard/          # å‰ç«¯å±•ç¤ºå±¤ï¼ˆDashboard UIï¼‰
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ app/           # Next.js App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ components/    # React Components (UI only)
â”‚   â”‚   â”‚   â”œâ”€â”€ hooks/         # Custom Hooks (useMetrics, useSSE)
â”‚   â”‚   â”‚   â”œâ”€â”€ lib/           # Client Utilities
â”‚   â”‚   â”‚   â””â”€â”€ styles/        # Tailwind CSS
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚
â”‚   â””â”€â”€ obs-edge/              # é‚Šç·£è¨ˆç®— API å±¤ï¼ˆEdge Workersï¼‰
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ handlers/      # API Handlers (tRPC routers)
â”‚       â”‚   â”œâ”€â”€ durable-objects/ # Realtime Aggregation
â”‚       â”‚   â”œâ”€â”€ middlewares/   # Rate Limiting, Auth, CORS
â”‚       â”‚   â””â”€â”€ utils/         # Edge Utilities
â”‚       â””â”€â”€ wrangler.toml
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ obs-types/             # å”¯ä¸€çœŸå¯¦è³‡æ–™å¥‘ç´„ï¼ˆSingle Source of Truthï¼‰
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/          # API Request/Response Types
â”‚   â”‚   â”‚   â”œâ”€â”€ domain/       # Domain Models (Metric, Event, Cost)
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/      # Zod Validation Schemas
â”‚   â”‚   â”‚   â””â”€â”€ constants/    # Shared Constants (NO magic numbers)
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚
â”‚   â”œâ”€â”€ llm-usage-collector/   # LLM æˆæœ¬è¿½è¹¤ SDK
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ collectors/    # Claude, GPT, Gemini Collectors
â”‚   â”‚   â”‚   â”œâ”€â”€ reporters/     # çµ±ä¸€å ±å‘Šæ ¼å¼ï¼ˆUnified Formatï¼‰
â”‚   â”‚   â”‚   â”œâ”€â”€ tracers/       # OpenTelemetry Integration
â”‚   â”‚   â”‚   â””â”€â”€ types/         # Collector Types
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚
â”‚   â””â”€â”€ shared-utils/          # å…±äº«å·¥å…·å‡½æ•¸ï¼ˆShared Utilitiesï¼‰
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ date/         # Date formatting, timezone
â”‚       â”‚   â”œâ”€â”€ validation/   # Common validators
â”‚       â”‚   â”œâ”€â”€ crypto/       # Encryption, hashing
â”‚       â”‚   â””â”€â”€ logger/       # Structured logging
â”‚       â””â”€â”€ package.json
â”‚
â””â”€â”€ infra/
    â”œâ”€â”€ cloudflare/            # IaC, éƒ¨ç½², æ¬Šé™ï¼ˆInfrastructure as Codeï¼‰
    â”‚   â”œâ”€â”€ workers/          # Wrangler configs
    â”‚   â”œâ”€â”€ pages/            # Pages configs
    â”‚   â”œâ”€â”€ terraform/        # Terraform IaC (optional)
    â”‚   â””â”€â”€ scripts/          # Deployment scripts
    â”‚
    â””â”€â”€ supabase/              # Schema, RLS, Migration
        â”œâ”€â”€ migrations/        # SQL Migrations (versioned)
        â”œâ”€â”€ seed.sql          # Seed Data
        â”œâ”€â”€ schema.sql        # Complete Schema
        â””â”€â”€ rls-policies.sql  # Row Level Security Policies
```

### æ¨¡çµ„è·è²¬æ¸…å–®ï¼ˆResponsibility Matrixï¼‰

| æ¨¡çµ„ | è·è²¬ (Responsibilities) | é‚Šç•Œ (Boundaries) | ä¾è³´ (Dependencies) | ç¦æ­¢äº‹é … (Prohibitions) |
|------|------------------------|-------------------|---------------------|------------------------|
| **obs-dashboard** | â€¢ å‰ç«¯UIå‘ˆç¾<br/>â€¢ SSE/WebSocketè¨‚é–±<br/>â€¢ åœ–è¡¨å¯è¦–åŒ–<br/>â€¢ ç”¨æˆ¶äº¤äº’ | â€¢ ä¸è™•ç†æ¥­å‹™é‚è¼¯<br/>â€¢ åƒ…æ¶ˆè²»API<br/>â€¢ ä¸ç›´æ¥è¨ªå•DB | obs-types<br/>tRPC client<br/>React Query | âŒ ä¸å¯ç¹éAPIç›´æ¥è¨ªå•DB<br/>âŒ ä¸å¯åœ¨å‰ç«¯åšè¤‡é›œè¨ˆç®—<br/>âŒ ä¸å¯ç¡¬ç·¨ç¢¼APIç«¯é» |
| **obs-edge** | â€¢ Workers + Durable Object API<br/>â€¢ å¯¦æ™‚èšåˆï¼ˆæ™‚é–“çª—å£ï¼‰<br/>â€¢ Rate Limiting<br/>â€¢ èªè­‰æˆæ¬Š | â€¢ ä¸è™•ç†å‰ç«¯æ¸²æŸ“<br/>â€¢ åƒ…æä¾›API<br/>â€¢ ä¸å­˜å„²é•·æœŸç‹€æ…‹ | obs-types<br/>Supabase<br/>KV<br/>R2 | âŒ ä¸å¯åŸ·è¡Œé•·æ™‚é–“æ“ä½œï¼ˆ>10sï¼‰<br/>âŒ ä¸å¯åœ¨Workeråšè¤‡é›œAIæ¨ç†<br/>âŒ ä¸å¯ç¹éRate Limiting |
| **obs-types** | â€¢ å”¯ä¸€çœŸå¯¦è³‡æ–™å¥‘ç´„<br/>â€¢ Zod schemas<br/>â€¢ Type definitions<br/>â€¢ Constants | â€¢ ä¸åŒ…å«å¯¦ä½œé‚è¼¯<br/>â€¢ åƒ…é¡å‹å®šç¾©<br/>â€¢ ç´”è³‡æ–™çµæ§‹ | Zod | âŒ ä¸å¯åœ¨æ­¤åŒ…å«æ¥­å‹™é‚è¼¯<br/>âŒ ä¸å¯ä¾è³´å…¶ä»–packages<br/>âŒ ä¸å¯æœ‰å‰¯ä½œç”¨ï¼ˆside effectsï¼‰ |
| **llm-usage-collector** | â€¢ ä¸‰æ¨¡å‹çµ±ä¸€å ±å‘Šæ ¼å¼<br/>â€¢ æˆæœ¬è¨ˆç®—<br/>â€¢ ä½¿ç”¨é‡è¿½è¹¤<br/>â€¢ OpenTelemetry Tracing | â€¢ ä¸è™•ç†å„²å­˜<br/>â€¢ åƒ…æ”¶é›†èˆ‡æ ¼å¼åŒ–<br/>â€¢ ä¸å‘¼å«LLM API | obs-types<br/>OpenTelemetry | âŒ ä¸å¯ç›´æ¥å¯«å…¥DB<br/>âŒ ä¸å¯ä¿®æ”¹metricæ ¼å¼<br/>âŒ ä¸å¯å„²å­˜API keys |
| **infra/cloudflare** | â€¢ IaCé…ç½®<br/>â€¢ éƒ¨ç½²è…³æœ¬<br/>â€¢ æ¬Šé™ç®¡ç†<br/>â€¢ ç’°å¢ƒè®Šæ•¸ç®¡ç† | â€¢ ä¸åŒ…å«æ‡‰ç”¨ä»£ç¢¼<br/>â€¢ åƒ…åŸºç¤è¨­æ–½é…ç½® | Wrangler CLI<br/>Terraform (optional) | âŒ ä¸å¯åŒ…å«æ‡‰ç”¨é‚è¼¯<br/>âŒ ä¸å¯ç¡¬ç·¨ç¢¼secrets<br/>âŒ ä¸å¯æ‰‹å‹•éƒ¨ç½²ï¼ˆé ˆè‡ªå‹•åŒ–ï¼‰ |
| **infra/supabase** | â€¢ Schemaå®šç¾©<br/>â€¢ RLS policies<br/>â€¢ Migration pipeline<br/>â€¢ Seed data | â€¢ ä¸è™•ç†æ‡‰ç”¨é‚è¼¯<br/>â€¢ åƒ…è³‡æ–™åº«çµæ§‹ | Supabase CLI<br/>PostgreSQL | âŒ ä¸å¯åœ¨migrationä¸­åŒ…å«æ‡‰ç”¨é‚è¼¯<br/>âŒ ä¸å¯ç¹éRLS<br/>âŒ ä¸å¯æ‰‹å‹•ä¿®æ”¹production schema |

### æ¨¡çµ„é–“é€šè¨Šå”è­°ï¼ˆCommunication Protocolsï¼‰

```mermaid
graph TB
    subgraph "Frontend Layer"
        A[obs-dashboard<br/>Next.js + React]
    end

    subgraph "Edge Layer"
        B[obs-edge<br/>Cloudflare Workers]
        C[Durable Objects<br/>Realtime Aggregation]
    end

    subgraph "Data Layer"
        D[(NAS PostgreSQL<br/>Primary DB)]
        E[(Supabase PostgreSQL<br/>Secondary/API)]
        F[(Supabase Vector<br/>pgvector)]
        G[(Cloudflare KV<br/>Cache)]
        H[(R2 Storage<br/>Cold Data)]
    end

    subgraph "External Services"
        I[Claude API]
        J[GPT API]
        K[Gemini API]
        L[Prometheus<br/>Metrics]
    end

    subgraph "SDK Layer"
        M[llm-usage-collector<br/>SDK]
    end

    A -->|tRPC + SSE| B
    A -->|WebSocket| C
    B -->|SQL| D
    B -->|SQL Read| E
    B -->|Vector Search| F
    B -->|Read/Write| G
    B -->|Archive| H
    C -->|Aggregation| B

    M -->|HTTP Report| B
    M -.->|LLM Calls| I
    M -.->|LLM Calls| J
    M -.->|LLM Calls| K

    D -->|Backup| H
    E -->|Replication| D
    B -->|Metrics Export| L

    style A fill:#38b2ac
    style B fill:#38b2ac
    style C fill:#4299e1
    style D fill:#ed8936
    style E fill:#ed8936
    style F fill:#805ad5
    style M fill:#48bb78
```

### è·¨æ¨¡çµ„å”ä½œç¯„ä¾‹ï¼ˆCross-Module Exampleï¼‰

#### å ´æ™¯ï¼šæ–°å¢ LLM æˆæœ¬è¿½è¹¤åŠŸèƒ½

```typescript
// âœ… CORRECT: éµå¾ªæ¨¡çµ„é‚Šç•Œ

// Step 1: obs-types å®šç¾©å¥‘ç´„ï¼ˆSingle Source of Truthï¼‰
// packages/obs-types/src/domain/cost.ts
export interface LLMCost {
  id: string;
  model: string;
  provider: 'claude' | 'gpt' | 'gemini';
  inputTokens: number;
  outputTokens: number;
  cost: number;
  timestamp: Date;
}

// packages/obs-types/src/schemas/cost.ts
import { z } from 'zod';
export const llmCostSchema = z.object({
  model: z.string(),
  provider: z.enum(['claude', 'gpt', 'gemini']),
  inputTokens: z.number().int().min(0),
  outputTokens: z.number().int().min(0),
  cost: z.number().min(0),
  timestamp: z.date()
});

// Step 2: llm-usage-collector æ”¶é›†æ•¸æ“š
// packages/llm-usage-collector/src/reporters/unified-reporter.ts
import { LLMCost, llmCostSchema } from '@obs/types';

export class UnifiedReporter {
  async report(cost: LLMCost): Promise<void> {
    const validated = llmCostSchema.parse(cost); // ä½¿ç”¨å…±äº«schemaé©—è­‰
    await this.sendToEdge(validated);
  }
}

// Step 3: obs-edge æ¥æ”¶ä¸¦å­˜å„²
// apps/obs-edge/src/handlers/cost.ts
import { LLMCost, llmCostSchema } from '@obs/types';

export const costRouter = router({
  report: procedure
    .input(llmCostSchema) // ä½¿ç”¨å…±äº«schemaé©—è­‰
    .mutation(async ({ input, ctx }) => {
      await ctx.db.insert(llmCosts).values(input);
      await ctx.cache.invalidate('costs:latest');
    })
});

// Step 4: obs-dashboard å±•ç¤º
// apps/obs-dashboard/src/hooks/useCosts.ts
import { LLMCost } from '@obs/types';

export function useCosts() {
  return trpc.cost.list.useQuery<LLMCost[]>();
}
```

---

## ğŸ§± CI/CD Gate Policyï¼ˆå“è³ªé–˜é–€ï¼‰

### Phase å“è³ªé–˜é–€æ¨™æº–

**æ¯å€‹ Phase å¿…é ˆé”åˆ° >= 85/100 æ‰èƒ½é€²å…¥ä¸‹ä¸€éšæ®µ**

#### å“è³ªåˆ†æ•¸è¨ˆç®—å…¬å¼

```typescript
å“è³ªåˆ†æ•¸ = (
  åŠŸèƒ½å®Œæ•´æ€§ Ã— 0.25 +   // æ‰€æœ‰äº¤ä»˜ç‰©100%å®Œæˆ
  æ¸¬è©¦è¦†è“‹ç‡ Ã— 0.20 +   // >= 80% coverage
  ä»£ç¢¼å“è³ª Ã— 0.20 +     // Lint 0 errors, TypeScript 100% strict
  æ€§èƒ½æŒ‡æ¨™ Ã— 0.15 +     // P95 < SLA target
  å®‰å…¨æ€§ Ã— 0.10 +       // 0 critical/high vulnerabilities
  æ–‡æª”å®Œæ•´åº¦ Ã— 0.10     // >= 90% documentation
) Ã— 100

é€šéæ¨™æº–: >= 85/100
å„ªç§€æ¨™æº–: >= 90/100
```

### è‡ªå‹•åŒ–æª¢æŸ¥æ¸…å–®ï¼ˆCI/CD Gatesï¼‰

æ¯æ¬¡æäº¤ï¼ˆCommitï¼‰/ PR å‰å¿…é ˆé€šéä»¥ä¸‹ 6 å¤§æª¢æŸ¥ï¼š

#### âœ… 1. Lint Checkï¼ˆä»£ç¢¼é¢¨æ ¼ï¼‰

```bash
# ESLint + Prettier
pnpm lint                # Check all packages
pnpm format:check        # Check formatting

# é€šéæ¨™æº–
âœ“ 0 errors
âœ“ 0 warnings (å…è¨±æœ€å¤š 5 å€‹ info level)
âœ“ æ‰€æœ‰æ–‡ä»¶æ ¼å¼ä¸€è‡´
```

**é…ç½®ç¯„ä¾‹ï¼š**
```json
// .eslintrc.json
{
  "extends": ["next/core-web-vitals", "prettier"],
  "rules": {
    "no-console": "warn",
    "no-debugger": "error",
    "@typescript-eslint/no-explicit-any": "error",
    "@typescript-eslint/no-unused-vars": "error"
  }
}
```

#### âœ… 2. Type Checkï¼ˆé¡å‹æª¢æŸ¥ï¼‰

```bash
# TypeScript Strict Mode
pnpm typecheck           # All packages
tsc --noEmit --strict    # Manual check

# é€šéæ¨™æº–
âœ“ 0 type errors
âœ“ 100% type coverage
âœ“ No 'any' types (é™¤éæ˜ç¢ºæ¨™è¨» @ts-expect-error)
âœ“ All functions have return types
```

**tsconfig.json è¦æ±‚ï¼š**
```json
{
  "compilerOptions": {
    "strict": true,
    "noImplicitAny": true,
    "strictNullChecks": true,
    "strictFunctionTypes": true,
    "strictPropertyInitialization": true,
    "noImplicitThis": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true
  }
}
```

#### âœ… 3. Unit Test Coverageï¼ˆå–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ï¼‰

```bash
# Vitest with Coverage
pnpm test:coverage

# é€šéæ¨™æº–
âœ“ Test Coverage: >= 80%
  â”œâ”€ Statements: >= 80%
  â”œâ”€ Branches: >= 75%
  â”œâ”€ Functions: >= 80%
  â””â”€ Lines: >= 80%
âœ“ All tests passing: 100%
âœ“ No skipped tests (é™¤éæ¨™è¨» JIRA ticket)
```

**è¦†è“‹ç‡å ±å‘Šç¯„ä¾‹ï¼š**
```
File                  | % Stmts | % Branch | % Funcs | % Lines |
----------------------|---------|----------|---------|---------|
All files             |   85.23 |    78.45 |   88.12 |   85.67 |
 obs-edge/handlers    |   92.15 |    85.33 |   94.44 |   93.21 |
 obs-types/schemas    |   100.0 |    100.0 |   100.0 |   100.0 |
 llm-collector        |   78.92 |    72.11 |   82.35 |   79.45 | âš ï¸
```

#### âœ… 4. E2E Testï¼ˆç«¯å°ç«¯æ¸¬è©¦ï¼‰

```bash
# Playwright E2E Tests
pnpm test:e2e
pnpm test:e2e:ui     # With UI mode

# é€šéæ¨™æº–
âœ“ Critical user flows: 100% passing
  â”œâ”€ Dashboard load & metrics display
  â”œâ”€ Real-time updates (SSE)
  â”œâ”€ Cost filtering & export
  â””â”€ LLM usage tracking
âœ“ Browser compatibility: Chrome, Firefox, Safari
âœ“ Performance: P95 < 3s (first contentful paint)
âœ“ Accessibility: WCAG 2.1 AA compliance
```

**E2E æ¸¬è©¦ç¯„ä¾‹ï¼š**
```typescript
// e2e/dashboard.spec.ts
test('dashboard loads and displays metrics', async ({ page }) => {
  await page.goto('/dashboard');

  // Check metrics loaded
  await expect(page.locator('[data-testid="metrics-chart"]')).toBeVisible();

  // Check real-time updates
  const metricBefore = await page.locator('[data-testid="total-cost"]').textContent();
  await page.waitForTimeout(5000); // Wait for SSE update
  const metricAfter = await page.locator('[data-testid="total-cost"]').textContent();
  expect(metricAfter).not.toBe(metricBefore);
});
```

#### âœ… 5. No Critical Dependency Warning

```bash
# Check for vulnerable dependencies
pnpm audit --production
pnpm outdated

# é€šéæ¨™æº–
âœ“ 0 critical vulnerabilities
âœ“ 0 high vulnerabilities
âœ“ Medium/Low: Review and document exceptions
âœ“ All dependencies up-to-date (within 3 months)
```

**ä¾è³´ç®¡ç†ç­–ç•¥ï¼š**
- æ¯æœˆç¬¬ä¸€é€±åŸ·è¡Œ `pnpm update --interactive`
- é‡å¤§å®‰å…¨æ¼æ´ï¼š24å°æ™‚å…§ä¿®å¾©
- é«˜å±æ¼æ´ï¼š7å¤©å…§ä¿®å¾©
- ä¸­å±æ¼æ´ï¼š30å¤©å…§ä¿®å¾©

#### âœ… 6. Security Scanï¼ˆå®‰å…¨æƒæï¼‰

```bash
# Snyk / CodeQL / OWASP ZAP
pnpm security:scan
snyk test --all-projects
codeql database analyze

# é€šéæ¨™æº–
âœ“ 0 critical security issues
âœ“ 0 high security issues
âœ“ API keys not hardcoded
âœ“ No sensitive data exposure in logs
âœ“ SQL injectioné˜²è­· (Parameterized queries)
âœ“ XSSé˜²è­· (Input sanitization)
âœ“ CSRFé˜²è­· (Token validation)
```

**å®‰å…¨æª¢æŸ¥æ¸…å–®ï¼š**
```yaml
Authentication:
  - [x] JWT tokens with expiration
  - [x] Refresh token rotation
  - [x] Password hashing (bcrypt/argon2)

Authorization:
  - [x] Row Level Security (RLS) policies
  - [x] Role-based access control (RBAC)
  - [x] Least privilege principle

Data Protection:
  - [x] HTTPS enforced (no HTTP)
  - [x] Sensitive data encrypted at rest
  - [x] API keys in environment variables
  - [x] Input validation (Zod schemas)

Audit & Compliance:
  - [x] Audit logs for critical operations
  - [x] GDPR compliance (data deletion)
  - [x] Rate limiting (DDoS protection)
```

### GitHub Actions CI/CD Pipeline

```yaml
# .github/workflows/ci.yml
name: CI/CD Quality Gates

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  quality-gate:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
        with:
          version: 8
      - uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'pnpm'

      - name: Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: âœ… Gate 1 - Lint Check
        run: pnpm lint

      - name: âœ… Gate 2 - Type Check
        run: pnpm typecheck

      - name: âœ… Gate 3 - Unit Tests
        run: pnpm test:coverage

      - name: Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info

      - name: âœ… Gate 4 - E2E Tests
        run: pnpm test:e2e

      - name: âœ… Gate 5 - Dependency Audit
        run: pnpm audit --production --audit-level=high

      - name: âœ… Gate 6 - Security Scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: Build
        run: pnpm build

      - name: Deploy Preview (PR only)
        if: github.event_name == 'pull_request'
        run: pnpm deploy:preview
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}

      - name: Deploy Production (main branch only)
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: pnpm deploy:production
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}

  performance-test:
    runs-on: ubuntu-latest
    needs: quality-gate
    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4
      - name: Run k6 Load Test
        uses: grafana/k6-action@v0.3.1
        with:
          filename: tests/load/scenario.js
          cloud: true
          token: ${{ secrets.K6_CLOUD_TOKEN }}
```

### Branch Protection Rulesï¼ˆåˆ†æ”¯ä¿è­·è¦å‰‡ï¼‰

**main / production åˆ†æ”¯å¿…é ˆè¨­å®šï¼š**
```yaml
Branch Protection:
  - Require pull request reviews: 2 approvals minimum
  - Require status checks to pass:
    âœ“ Lint Check
    âœ“ Type Check
    âœ“ Unit Tests (>= 80% coverage)
    âœ“ E2E Tests
    âœ“ Security Scan
  - Require branches to be up to date
  - Require linear history (no merge commits)
  - Require signed commits (GPG)
  - Include administrators: Yes
  - Restrict who can push: CI/CD bot only
```

---

## ğŸªª æ¨¡å‹æˆæ¬Šèˆ‡ç‰ˆæ§ç­–ç•¥

### AI å›æ‡‰è¿½æº¯æ€§ï¼ˆAI Response Traceabilityï¼‰

**æ‰€æœ‰ AI å›æ‡‰ï¼ˆClaude/Gemini/GPTï¼‰å‡é ˆä¿å­˜è‡³ `/logs/ai-trace`**ï¼Œç”¨æ–¼å¯è¿½æº¯æ€§ã€å¯©æ ¸èˆ‡åˆè¦ã€‚

#### æ—¥èªŒæ ¼å¼è¦ç¯„

```typescript
// /logs/ai-trace/{YYYY-MM-DD}/{HH-mm-ss}-{model}-{requestId}.json
interface AITraceLog {
  // åŸºæœ¬è³‡è¨Š
  timestamp: string;          // ISO 8601æ ¼å¼
  requestId: string;          // UUID v4
  model: string;              // "claude-3-5-sonnet-20241022"
  provider: 'anthropic' | 'openai' | 'google';

  // è«‹æ±‚å…§å®¹
  request: {
    messages: Message[];
    temperature: number;
    max_tokens: number;
    system?: string;
  };

  // å›æ‡‰å…§å®¹
  response: {
    content: string;
    usage: {
      prompt_tokens: number;
      completion_tokens: number;
      total_tokens: number;
    };
    cost: number;            // USD
    latency: number;         // milliseconds
    finish_reason: string;
  };

  // ä»»å‹™å…ƒæ•¸æ“š
  task: {
    type: 'architecture_design' | 'code_generation' | 'code_review' | 'documentation' | 'testing';
    complexity: number;      // 1-10
    security_critical: boolean;
    phase: string;           // "Phase 1"
  };

  // è¿½æº¯è³‡è¨Š
  metadata: {
    commit: string;          // Git commit hash
    branch: string;
    user: string;            // "claude-code" or actual user
    session_id: string;
    parent_request_id?: string; // For multi-turn conversations
  };

  // åˆè¦æ¨™è¨˜
  compliance: {
    confidential: boolean;   // æ˜¯å¦åŒ…å«æ•æ„Ÿè³‡è¨Š
    retention_days: number;  // ä¿ç•™å¤©æ•¸ï¼ˆé è¨­180å¤©ï¼‰
    gdpr_compliant: boolean;
  };
}
```

#### å„²å­˜èˆ‡æŸ¥è©¢ç¯„ä¾‹

```typescript
// services/ai-trace-logger.ts
import { createHash } from 'crypto';
import { writeFile, mkdir } from 'fs/promises';
import path from 'path';

export class AITraceLogger {
  private baseDir = './logs/ai-trace';

  async log(trace: AITraceLog): Promise<void> {
    // å‰µå»ºæ—¥æœŸç›®éŒ„
    const date = new Date(trace.timestamp);
    const dateDir = date.toISOString().split('T')[0];
    const dirPath = path.join(this.baseDir, dateDir);
    await mkdir(dirPath, { recursive: true });

    // æ–‡ä»¶åï¼š{æ™‚é–“}-{æ¨¡å‹}-{requestId}.json
    const time = date.toTimeString().split(' ')[0].replace(/:/g, '-');
    const filename = `${time}-${trace.model}-${trace.requestId}.json`;
    const filePath = path.join(dirPath, filename);

    // å¯«å…¥æ—¥èªŒ
    await writeFile(filePath, JSON.stringify(trace, null, 2));

    // åŒæ­¥åˆ° Supabaseï¼ˆç•°æ­¥ï¼Œä¸é˜»å¡ï¼‰
    this.syncToSupabase(trace).catch(console.error);
  }

  private async syncToSupabase(trace: AITraceLog): Promise<void> {
    await supabase.from('ai_trace_logs').insert({
      request_id: trace.requestId,
      timestamp: trace.timestamp,
      model: trace.model,
      provider: trace.provider,
      cost: trace.response.cost,
      latency: trace.response.latency,
      tokens: trace.response.usage.total_tokens,
      task_type: trace.task.type,
      phase: trace.task.phase,
      confidential: trace.compliance.confidential
    });
  }

  // æŸ¥è©¢æœ€è¿‘çš„ AI äº’å‹•
  async queryRecent(limit: number = 10): Promise<AITraceLog[]> {
    const { data } = await supabase
      .from('ai_trace_logs')
      .select('*')
      .order('timestamp', { ascending: false })
      .limit(limit);

    return data || [];
  }

  // æŸ¥è©¢ç‰¹å®š Phase çš„æˆæœ¬
  async getCostByPhase(phase: string): Promise<number> {
    const { data } = await supabase
      .from('ai_trace_logs')
      .select('cost')
      .eq('phase', phase);

    return data?.reduce((sum, row) => sum + row.cost, 0) || 0;
  }
}
```

### Prompt æ¨¡æ¿ç‰ˆæœ¬åŒ–ç®¡ç†

**é‡è¦ Prompt æ¨¡æ¿éœ€ç‰ˆæœ¬åŒ–ç®¡ç†ï¼ˆGit tag + meta.jsonï¼‰**

#### ç›®éŒ„çµæ§‹

```
prompts/
â”œâ”€â”€ architecture-design/
â”‚   â”œâ”€â”€ v1.0.0/
â”‚   â”‚   â”œâ”€â”€ prompt.md
â”‚   â”‚   â”œâ”€â”€ meta.json
â”‚   â”‚   â””â”€â”€ examples/
â”‚   â”‚       â”œâ”€â”€ input1.md
â”‚   â”‚       â””â”€â”€ output1.md
â”‚   â”œâ”€â”€ v1.1.0/
â”‚   â”‚   â”œâ”€â”€ prompt.md
â”‚   â”‚   â”œâ”€â”€ meta.json
â”‚   â”‚   â””â”€â”€ CHANGELOG.md
â”‚   â””â”€â”€ latest -> v1.1.0  # Symlink
â”‚
â”œâ”€â”€ code-review/
â”‚   â””â”€â”€ v1.0.0/
â”‚       â”œâ”€â”€ prompt.md
â”‚       â””â”€â”€ meta.json
â”‚
â””â”€â”€ security-audit/
    â””â”€â”€ v1.0.0/
        â”œâ”€â”€ prompt.md
        â”œâ”€â”€ meta.json
        â””â”€â”€ checklist.md
```

#### meta.json è¦ç¯„

```json
{
  "version": "1.1.0",
  "created": "2025-01-07",
  "updated": "2025-01-15",
  "author": "Claude Code",
  "reviewers": ["John Doe", "Jane Smith"],

  "description": "System architecture design prompt for complex multi-module systems",

  "tags": [
    "architecture",
    "system-design",
    "enterprise",
    "multi-tenant"
  ],

  "confidential": false,

  "model_requirements": {
    "min_complexity": 8,
    "preferred_model": "claude-3-5-sonnet",
    "fallback_models": ["gpt-4o", "gpt-4o-mini"],
    "min_context_window": 100000,
    "temperature": 0.7,
    "max_tokens": 4096
  },

  "validation": {
    "required_sections": [
      "System Overview",
      "Architecture Diagram",
      "Component Responsibilities",
      "Security Considerations",
      "Scalability Plan"
    ],
    "min_length": 2000,
    "max_length": 10000
  },

  "changelog": [
    {
      "version": "1.1.0",
      "date": "2025-01-15",
      "changes": [
        "Added multi-tenant considerations",
        "Enhanced security section",
        "Added cost estimation template"
      ]
    },
    {
      "version": "1.0.0",
      "date": "2025-01-07",
      "changes": [
        "Initial version"
      ]
    }
  ],

  "deprecation": {
    "deprecated": false,
    "deprecated_date": null,
    "replacement_version": null
  }
}
```

#### Prompt ç‰ˆæœ¬ç®¡ç†å·¥å…·

```typescript
// tools/prompt-version-manager.ts
import { readFile, writeFile } from 'fs/promises';
import path from 'path';
import semver from 'semver';

export class PromptVersionManager {
  private promptsDir = './prompts';

  // è¼‰å…¥ç‰¹å®šç‰ˆæœ¬çš„ Prompt
  async load(
    category: string,
    version: string = 'latest'
  ): Promise<{ prompt: string; meta: PromptMeta }> {
    const versionDir = version === 'latest'
      ? path.join(this.promptsDir, category, 'latest')
      : path.join(this.promptsDir, category, `v${version}`);

    const [prompt, meta] = await Promise.all([
      readFile(path.join(versionDir, 'prompt.md'), 'utf-8'),
      readFile(path.join(versionDir, 'meta.json'), 'utf-8').then(JSON.parse)
    ]);

    return { prompt, meta };
  }

  // å‰µå»ºæ–°ç‰ˆæœ¬
  async createVersion(
    category: string,
    newVersion: string,
    changes: string[]
  ): Promise<void> {
    // é©—è­‰ç‰ˆæœ¬è™Ÿ
    if (!semver.valid(newVersion)) {
      throw new Error(`Invalid version: ${newVersion}`);
    }

    // è¼‰å…¥ç•¶å‰æœ€æ–°ç‰ˆæœ¬
    const { prompt: oldPrompt, meta: oldMeta } = await this.load(category);

    // ç¢ºèªç‰ˆæœ¬éå¢
    if (!semver.gt(newVersion, oldMeta.version)) {
      throw new Error(
        `New version ${newVersion} must be greater than current ${oldMeta.version}`
      );
    }

    // å‰µå»ºæ–°ç‰ˆæœ¬ç›®éŒ„
    const newVersionDir = path.join(this.promptsDir, category, `v${newVersion}`);
    await mkdir(newVersionDir, { recursive: true });

    // æ›´æ–° meta.json
    const newMeta = {
      ...oldMeta,
      version: newVersion,
      updated: new Date().toISOString().split('T')[0],
      changelog: [
        {
          version: newVersion,
          date: new Date().toISOString().split('T')[0],
          changes
        },
        ...oldMeta.changelog
      ]
    };

    // å¯«å…¥æ–‡ä»¶
    await Promise.all([
      writeFile(path.join(newVersionDir, 'prompt.md'), oldPrompt),
      writeFile(path.join(newVersionDir, 'meta.json'), JSON.stringify(newMeta, null, 2)),
      writeFile(path.join(newVersionDir, 'CHANGELOG.md'), this.generateChangelog(newMeta))
    ]);

    console.log(`âœ… Created new version: ${category} v${newVersion}`);
  }

  // æ£„ç”¨èˆŠç‰ˆæœ¬
  async deprecate(
    category: string,
    version: string,
    replacementVersion: string
  ): Promise<void> {
    const versionDir = path.join(this.promptsDir, category, `v${version}`);
    const metaPath = path.join(versionDir, 'meta.json');

    const meta = JSON.parse(await readFile(metaPath, 'utf-8'));
    meta.deprecation = {
      deprecated: true,
      deprecated_date: new Date().toISOString().split('T')[0],
      replacement_version: replacementVersion
    };

    await writeFile(metaPath, JSON.stringify(meta, null, 2));
    console.log(`âš ï¸  Deprecated: ${category} v${version} â†’ use v${replacementVersion}`);
  }

  private generateChangelog(meta: PromptMeta): string {
    return meta.changelog.map(entry => `
## ${entry.version} (${entry.date})

${entry.changes.map(c => `- ${c}`).join('\n')}
    `).join('\n');
  }
}

// ä½¿ç”¨ç¯„ä¾‹
const manager = new PromptVersionManager();

// è¼‰å…¥æœ€æ–°ç‰ˆæœ¬
const { prompt, meta } = await manager.load('architecture-design');

// å‰µå»ºæ–°ç‰ˆæœ¬
await manager.createVersion('architecture-design', '1.2.0', [
  'Added cost optimization section',
  'Enhanced security checklist'
]);

// æ£„ç”¨èˆŠç‰ˆæœ¬
await manager.deprecate('architecture-design', '1.0.0', '1.2.0');
```

### ä¼æ¥­ç§æœ‰ Prompt æ¨™è¨˜

**è‹¥æœ‰ä¼æ¥­ç§æœ‰ Promptï¼Œéœ€æ¨™è¨˜ã€ŒConfidentialã€**

```markdown
<!-- CONFIDENTIAL: Internal Use Only -->
<!-- Classification: Company Confidential -->
<!-- DO NOT SHARE OUTSIDE ORGANIZATION -->
<!-- Retention: Delete after 180 days -->

# Enterprise Architecture Review Prompt (CONFIDENTIAL)

> **âš ï¸ This prompt contains proprietary methodologies and trade secrets**
> **Unauthorized distribution is prohibited**

## Confidential Section: Competitive Analysis Framework

[... ä¼æ¥­å°ˆæœ‰å…§å®¹ ...]

## Security Assessment Criteria (Internal Only)

[... å…§éƒ¨å®‰å…¨æ¨™æº– ...]

---

**Document Classification**: Company Confidential
**Clearance Level**: L3 (Senior Engineering+)
**Review Date**: 2025-01-07
**Next Review**: 2025-07-07 (6 months)
```

#### Confidential Prompt ç®¡ç†è¦ç¯„

```yaml
Confidential Prompt Rules:
  Storage:
    - Must be encrypted at rest (AES-256)
    - Access controlled by RBAC (Role-Based Access Control)
    - Audit all access (who, when, what)

  Transmission:
    - HTTPS/TLS 1.3 only
    - No email/Slack transmission
    - Use secure document sharing (e.g., 1Password, Vault)

  Lifecycle:
    - Auto-expire after 180 days (default)
    - Require re-approval for extension
    - Watermark all exports

  Compliance:
    - GDPR Article 32 (Security of processing)
    - ISO 27001 controls
    - SOC 2 Type II audit trail
```

---

## ğŸ§  çŸ¥è­˜å¾ªç’°ç³»çµ±åŸºç¤åŸç†

### å‘é‡å„²å­˜çµæ§‹ï¼ˆSupabase Vectorï¼‰

#### Schema è¨­è¨ˆ

```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Knowledge Base Table
CREATE TABLE knowledge_base (
  -- Primary Key
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),

  -- Content
  title TEXT NOT NULL,
  content TEXT NOT NULL,
  summary TEXT,
  type VARCHAR(50) NOT NULL,

  -- Vector Embedding (Gemini text-embedding-004: 768 dimensions)
  embedding VECTOR(768),

  -- Metadata
  phase VARCHAR(20),
  tags TEXT[],
  author VARCHAR(100),
  complexity INT CHECK (complexity BETWEEN 1 AND 10),
  security_level VARCHAR(20) DEFAULT 'public',

  -- Relations
  parent_id UUID REFERENCES knowledge_base(id),
  related_commits TEXT[],
  related_docs TEXT[],

  -- Lifecycle
  is_archived BOOLEAN DEFAULT FALSE,
  archived_at TIMESTAMPTZ,
  retention_days INT DEFAULT 180,

  -- Constraints
  CONSTRAINT knowledge_base_type_check CHECK (
    type IN ('dev_log', 'adr', 'solution', 'learning', 'prompt_template')
  ),
  CONSTRAINT knowledge_base_security_check CHECK (
    security_level IN ('public', 'internal', 'confidential', 'restricted')
  )
);

-- Indexes for Performance
CREATE INDEX knowledge_base_embedding_idx
  ON knowledge_base
  USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

CREATE INDEX knowledge_base_content_idx
  ON knowledge_base
  USING gin(to_tsvector('english', content));

CREATE INDEX knowledge_base_tags_idx
  ON knowledge_base
  USING gin(tags);

CREATE INDEX knowledge_base_created_idx
  ON knowledge_base (created_at DESC);

-- Full-Text Search Function
CREATE OR REPLACE FUNCTION search_knowledge(
  query_text TEXT,
  match_count INT DEFAULT 10
)
RETURNS SETOF knowledge_base
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT *
  FROM knowledge_base
  WHERE to_tsvector('english', content) @@ plainto_tsquery('english', query_text)
    AND NOT is_archived
  ORDER BY ts_rank(to_tsvector('english', content), plainto_tsquery('english', query_text)) DESC
  LIMIT match_count;
END;
$$;

-- Vector Similarity Search Function
CREATE OR REPLACE FUNCTION match_knowledge(
  query_embedding VECTOR(768),
  match_threshold FLOAT DEFAULT 0.7,
  match_count INT DEFAULT 5
)
RETURNS TABLE (
  id UUID,
  title TEXT,
  content TEXT,
  similarity FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    kb.id,
    kb.title,
    kb.content,
    1 - (kb.embedding <=> query_embedding) AS similarity
  FROM knowledge_base kb
  WHERE 1 - (kb.embedding <=> query_embedding) > match_threshold
    AND NOT kb.is_archived
  ORDER BY kb.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;

-- Hybrid Search (Full-Text + Vector)
CREATE OR REPLACE FUNCTION hybrid_search(
  query_text TEXT,
  query_embedding VECTOR(768),
  match_count INT DEFAULT 10
)
RETURNS TABLE (
  id UUID,
  title TEXT,
  content TEXT,
  text_score FLOAT,
  vector_score FLOAT,
  combined_score FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  WITH text_search AS (
    SELECT
      kb.id,
      ts_rank(to_tsvector('english', kb.content), plainto_tsquery('english', query_text)) AS score
    FROM knowledge_base kb
    WHERE to_tsvector('english', kb.content) @@ plainto_tsquery('english', query_text)
      AND NOT kb.is_archived
  ),
  vector_search AS (
    SELECT
      kb.id,
      1 - (kb.embedding <=> query_embedding) AS score
    FROM knowledge_base kb
    WHERE NOT kb.is_archived
  )
  SELECT
    kb.id,
    kb.title,
    kb.content,
    COALESCE(ts.score, 0) AS text_score,
    COALESCE(vs.score, 0) AS vector_score,
    (COALESCE(ts.score, 0) * 0.3 + COALESCE(vs.score, 0) * 0.7) AS combined_score
  FROM knowledge_base kb
  LEFT JOIN text_search ts ON kb.id = ts.id
  LEFT JOIN vector_search vs ON kb.id = vs.id
  WHERE (ts.score IS NOT NULL OR vs.score IS NOT NULL)
    AND NOT kb.is_archived
  ORDER BY combined_score DESC
  LIMIT match_count;
END;
$$;

-- Auto-Update Timestamp Trigger
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_knowledge_base_updated_at
  BEFORE UPDATE ON knowledge_base
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();

-- Row Level Security (RLS)
ALTER TABLE knowledge_base ENABLE ROW LEVEL SECURITY;

-- Public: Anyone can read public knowledge
CREATE POLICY "Public knowledge is viewable by everyone"
  ON knowledge_base
  FOR SELECT
  USING (security_level = 'public' AND NOT is_archived);

-- Internal: Authenticated users can read internal knowledge
CREATE POLICY "Internal knowledge for authenticated users"
  ON knowledge_base
  FOR SELECT
  USING (
    auth.role() = 'authenticated'
    AND security_level IN ('public', 'internal')
    AND NOT is_archived
  );

-- Confidential: Only specific roles can access
CREATE POLICY "Confidential knowledge for admins"
  ON knowledge_base
  FOR SELECT
  USING (
    auth.jwt() ->> 'role' IN ('admin', 'tech_lead')
    AND NOT is_archived
  );

-- Insert: Only authenticated users can insert
CREATE POLICY "Authenticated users can insert knowledge"
  ON knowledge_base
  FOR INSERT
  WITH CHECK (auth.role() = 'authenticated');

-- Update: Only owners or admins can update
CREATE POLICY "Owners and admins can update knowledge"
  ON knowledge_base
  FOR UPDATE
  USING (
    author = auth.jwt() ->> 'email'
    OR auth.jwt() ->> 'role' = 'admin'
  );
```

### çŸ¥è­˜å¾ªç’°å®Œæ•´æµç¨‹

```mermaid
sequenceDiagram
    participant Dev as Developer/Claude Code
    participant Logger as DevJournalLogger
    participant Embed as Gemini Embedding API
    participant Vector as Supabase Vector DB
    participant RAG as RAG Engine
    participant Agent as AI Agent (Claude/GPT)
    participant Feedback as Quality Feedback

    Note over Dev: é–‹ç™¼ä»»å‹™å®Œæˆ

    Dev->>Logger: commit knowledge<br/>(code, docs, ADRs, solutions)

    Logger->>Logger: Extract metadata<br/>(phase, tags, complexity)
    Logger->>Embed: generate embedding<br/>(text â†’ vector 768-dim)
    Embed-->>Logger: embedding vector
    Logger->>Vector: store with metadata<br/>(content + embedding)
    Vector-->>Logger: stored (id)

    Note over Agent: æ–°ä»»å‹™é–‹å§‹

    Agent->>RAG: semantic search<br/>(query: "similar task")
    RAG->>Embed: generate query embedding
    Embed-->>RAG: query vector
    RAG->>Vector: similarity search<br/>(cosine distance < 0.3)
    Vector-->>RAG: top K relevant docs

    RAG->>RAG: re-rank by relevance<br/>(hybrid: text + vector)
    RAG->>RAG: filter by security level
    RAG-->>Agent: enhanced context<br/>(relevant knowledge)

    Agent->>Agent: generate response<br/>with knowledge context
    Agent-->>Dev: improved response

    Dev->>Feedback: rate quality (1-10)
    Feedback->>Vector: update metadata<br/>(usage_count++, avg_rating)

    Note over Vector: Knowledge grows & improves

    par Background Process
        Vector->>Vector: auto-archive old knowledge<br/>(180 days retention)
        Vector->>Vector: compress rarely-used docs
        Vector->>Vector: update statistics
    end
```

### DevJournalLogger â†’ Ingestion â†’ Embeddings â†’ Retriever â†’ Fine-tune

#### 1. DevJournalLoggerï¼ˆçŸ¥è­˜è¨˜éŒ„å™¨ï¼‰

```typescript
// services/dev-journal-logger.ts
import { createClient } from '@supabase/supabase-js';
import { GoogleGenerativeAI } from '@google/generative-ai';

interface DevLogEntry {
  title: string;
  content: string;
  type: 'dev_log' | 'adr' | 'solution' | 'learning' | 'prompt_template';
  phase?: string;
  tags?: string[];
  complexity?: number;
  securityLevel?: 'public' | 'internal' | 'confidential' | 'restricted';
  relatedCommits?: string[];
}

export class DevJournalLogger {
  private supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_KEY!);
  private gemini = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

  async logDevelopment(entry: DevLogEntry): Promise<string> {
    // 1. Save to Markdown (local backup)
    const markdownPath = await this.saveToMarkdown(entry);

    // 2. Generate embedding
    const embedding = await this.generateEmbedding(entry.content);

    // 3. Extract summary
    const summary = await this.generateSummary(entry.content);

    // 4. Store to Supabase Vector
    const { data, error } = await this.supabase
      .from('knowledge_base')
      .insert({
        title: entry.title,
        content: entry.content,
        summary,
        type: entry.type,
        embedding,
        phase: entry.phase || 'Unknown',
        tags: entry.tags || [],
        author: process.env.USER || 'claude-code',
        complexity: entry.complexity || 5,
        security_level: entry.securityLevel || 'public',
        related_commits: entry.relatedCommits || []
      })
      .select('id')
      .single();

    if (error) {
      console.error('Failed to store knowledge:', error);
      throw error;
    }

    console.log(`âœ… Knowledge logged: ${entry.title} (${data.id})`);
    console.log(`ğŸ“ Markdown saved: ${markdownPath}`);

    return data.id;
  }

  private async saveToMarkdown(entry: DevLogEntry): Promise<string> {
    const date = new Date().toISOString().split('T')[0];
    const dirPath = `./knowledge/${date}`;
    await mkdir(dirPath, { recursive: true });

    const filename = `${entry.title.toLowerCase().replace(/\s+/g, '-')}.md`;
    const filePath = path.join(dirPath, filename);

    const markdown = `# ${entry.title}

**Type**: ${entry.type}
**Phase**: ${entry.phase || 'Unknown'}
**Date**: ${new Date().toISOString()}
**Tags**: ${entry.tags?.join(', ') || 'None'}
**Complexity**: ${entry.complexity || 'N/A'}/10

---

${entry.content}

---

**Related Commits**: ${entry.relatedCommits?.join(', ') || 'None'}
`;

    await writeFile(filePath, markdown);
    return filePath;
  }

  private async generateEmbedding(text: string): Promise<number[]> {
    const model = this.gemini.getGenerativeModel({ model: 'text-embedding-004' });
    const result = await model.embedContent(text);
    return result.embedding.values;
  }

  private async generateSummary(text: string): Promise<string> {
    // Use Gemini to generate concise summary
    const model = this.gemini.getGenerativeModel({ model: 'gemini-pro' });
    const prompt = `Summarize the following technical content in 2-3 sentences:\n\n${text}`;
    const result = await model.generateContent(prompt);
    return result.response.text();
  }

  // Log ADR (Architecture Decision Record)
  async logADR(decision: {
    title: string;
    context: string;
    decision: string;
    consequences: string;
    alternatives?: string;
  }): Promise<string> {
    const content = `
## Context
${decision.context}

## Decision
${decision.decision}

## Consequences
${decision.consequences}

${decision.alternatives ? `## Alternatives Considered\n${decision.alternatives}` : ''}
    `.trim();

    return this.logDevelopment({
      title: `ADR: ${decision.title}`,
      content,
      type: 'adr',
      tags: ['architecture', 'decision-record'],
      complexity: 8
    });
  }

  // Log Problem-Solution
  async logSolution(problem: string, solution: string, tags?: string[]): Promise<string> {
    const content = `
## Problem
${problem}

## Solution
${solution}
    `.trim();

    return this.logDevelopment({
      title: `Solution: ${problem.substring(0, 50)}...`,
      content,
      type: 'solution',
      tags: tags || ['problem-solving'],
      complexity: 6
    });
  }
}
```

#### 2. RAG Engineï¼ˆçŸ¥è­˜æª¢ç´¢å¼•æ“ï¼‰

```typescript
// services/rag-engine.ts
export class RAGEngine {
  private logger = new DevJournalLogger();
  private supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_KEY!);
  private gemini = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

  /**
   * Semantic search with hybrid approach (text + vector)
   */
  async retrieve(
    query: string,
    options: {
      topK?: number;
      minSimilarity?: number;
      filterTags?: string[];
      filterPhase?: string;
      securityLevel?: string;
    } = {}
  ): Promise<RetrievedDocument[]> {
    const {
      topK = 5,
      minSimilarity = 0.7,
      filterTags,
      filterPhase,
      securityLevel = 'public'
    } = options;

    // Generate query embedding
    const queryEmbedding = await this.generateEmbedding(query);

    // Hybrid search (text + vector)
    const { data, error } = await this.supabase.rpc('hybrid_search', {
      query_text: query,
      query_embedding: queryEmbedding,
      match_count: topK * 2 // Get more for filtering
    });

    if (error) {
      console.error('RAG retrieval failed:', error);
      return [];
    }

    // Filter by tags, phase, security level
    let results = data || [];

    if (filterTags && filterTags.length > 0) {
      results = results.filter(doc =>
        filterTags.some(tag => doc.tags?.includes(tag))
      );
    }

    if (filterPhase) {
      results = results.filter(doc => doc.phase === filterPhase);
    }

    if (securityLevel) {
      const levels = ['public', 'internal', 'confidential', 'restricted'];
      const maxLevel = levels.indexOf(securityLevel);
      results = results.filter(doc =>
        levels.indexOf(doc.security_level) <= maxLevel
      );
    }

    // Filter by similarity threshold
    results = results.filter(doc => doc.combined_score >= minSimilarity);

    // Limit to topK
    results = results.slice(0, topK);

    return results.map(doc => ({
      id: doc.id,
      title: doc.title,
      content: doc.content,
      summary: doc.summary,
      score: doc.combined_score,
      type: doc.type,
      tags: doc.tags
    }));
  }

  /**
   * Generate enhanced prompt with retrieved knowledge
   */
  async enhancePrompt(
    task: string,
    basePrompt: string
  ): Promise<{ prompt: string; sources: RetrievedDocument[] }> {
    // Retrieve relevant knowledge
    const knowledge = await this.retrieve(task, { topK: 3 });

    if (knowledge.length === 0) {
      return { prompt: basePrompt, sources: [] };
    }

    // Construct enhanced prompt
    const enhancedPrompt = `
${basePrompt}

## Relevant Knowledge Context

${knowledge.map((k, i) => `
### ${i + 1}. ${k.title} (Relevance: ${(k.score * 100).toFixed(1)}%)

${k.summary || k.content.substring(0, 500)}...

`).join('\n')}

## Task

${task}

**Instructions**: Please solve this task using the above knowledge context. Reference specific knowledge items if applicable.
    `.trim();

    return { prompt: enhancedPrompt, sources: knowledge };
  }

  private async generateEmbedding(text: string): Promise<number[]> {
    const model = this.gemini.getGenerativeModel({ model: 'text-embedding-004' });
    const result = await model.embedContent(text);
    return result.embedding.values;
  }
}
```

#### 3. AgentTrainingSystemï¼ˆAI è¨“ç·´ç³»çµ±ï¼‰

```typescript
// services/agent-training-system.ts
export class AgentTrainingSystem {
  private rag = new RAGEngine();
  private logger = new DevJournalLogger();

  /**
   * Before task execution: Retrieve relevant knowledge
   */
  async beforeTask(task: {
    description: string;
    type: string;
    complexity: number;
  }): Promise<{ enhancedPrompt: string; sources: RetrievedDocument[] }> {
    console.log(`ğŸ” Retrieving knowledge for task: ${task.description.substring(0, 50)}...`);

    // Retrieve relevant knowledge
    const knowledge = await this.rag.retrieve(task.description, {
      topK: 5,
      filterTags: [task.type],
      minSimilarity: 0.6
    });

    // Enhance prompt
    const { prompt, sources } = await this.rag.enhancePrompt(
      task.description,
      `You are an expert ${task.type} assistant. Your task complexity is ${task.complexity}/10.`
    );

    console.log(`âœ… Retrieved ${sources.length} relevant documents`);
    sources.forEach((s, i) => {
      console.log(`   ${i + 1}. ${s.title} (${(s.score * 100).toFixed(1)}% relevance)`);
    });

    return { enhancedPrompt: prompt, sources };
  }

  /**
   * After task execution: Log learning and feedback
   */
  async afterTask(task: {
    description: string;
    solution: string;
    quality: number; // 1-10
    timeSpent: number; // minutes
    usedKnowledge: string[]; // IDs of used knowledge
  }): Promise<void> {
    console.log(`ğŸ“ Logging learning from task...`);

    // Log the solution as new knowledge
    await this.logger.logDevelopment({
      title: `Solution: ${task.description.substring(0, 80)}`,
      content: task.solution,
      type: 'learning',
      tags: ['solution', 'training'],
      complexity: Math.ceil(task.timeSpent / 10), // Estimate complexity from time
      phase: process.env.CURRENT_PHASE
    });

    // Update usage statistics for used knowledge
    for (const knowledgeId of task.usedKnowledge) {
      await this.updateKnowledgeStats(knowledgeId, task.quality);
    }

    console.log(`âœ… Learning logged, knowledge stats updated`);
  }

  private async updateKnowledgeStats(
    knowledgeId: string,
    quality: number
  ): Promise<void> {
    const { data: current } = await this.supabase
      .from('knowledge_base')
      .select('usage_count, avg_rating')
      .eq('id', knowledgeId)
      .single();

    if (!current) return;

    const usageCount = (current.usage_count || 0) + 1;
    const avgRating = (
      ((current.avg_rating || 0) * (usageCount - 1) + quality) / usageCount
    );

    await this.supabase
      .from('knowledge_base')
      .update({
        usage_count: usageCount,
        avg_rating: avgRating,
        last_used_at: new Date().toISOString()
      })
      .eq('id', knowledgeId);
  }

  /**
   * Calculate learning curve metrics
   */
  async getLearningCurve(phase: string): Promise<{
    tasksCompleted: number;
    avgQuality: number;
    avgTimeSpent: number;
    knowledgeGrowth: number;
  }> {
    const { data: knowledge } = await this.supabase
      .from('knowledge_base')
      .select('created_at, avg_rating, usage_count')
      .eq('phase', phase)
      .eq('type', 'learning')
      .order('created_at', { ascending: true });

    if (!knowledge || knowledge.length === 0) {
      return {
        tasksCompleted: 0,
        avgQuality: 0,
        avgTimeSpent: 0,
        knowledgeGrowth: 0
      };
    }

    return {
      tasksCompleted: knowledge.length,
      avgQuality: knowledge.reduce((sum, k) => sum + (k.avg_rating || 0), 0) / knowledge.length,
      avgTimeSpent: 0, // TODO: Calculate from logs
      knowledgeGrowth: knowledge.length / 10 // Knowledge items per 10 tasks
    };
  }
}
```

### è‡ªå‹•æ¸…ç†æ©Ÿåˆ¶ï¼šéæœŸçŸ¥è­˜ 180 å¤©å¾Œå£“ç¸®å°å­˜

```sql
-- Auto-archive old knowledge (scheduled monthly)
CREATE OR REPLACE FUNCTION archive_old_knowledge()
RETURNS TABLE (archived_count INT, compressed_count INT) AS $$
DECLARE
  v_archived_count INT := 0;
  v_compressed_count INT := 0;
BEGIN
  -- Archive non-ADR knowledge older than 180 days
  WITH archived AS (
    UPDATE knowledge_base
    SET
      is_archived = TRUE,
      archived_at = NOW()
    WHERE
      updated_at < NOW() - INTERVAL '180 days'
      AND type != 'adr'  -- Keep ADRs forever
      AND NOT is_archived
    RETURNING *
  )
  SELECT COUNT(*) INTO v_archived_count FROM archived;

  -- Compress rarely-used knowledge (usage_count < 3, older than 90 days)
  WITH compressed AS (
    UPDATE knowledge_base
    SET
      content = LEFT(content, 500) || '... [Compressed]',  -- Keep only first 500 chars
      embedding = NULL  -- Remove embedding to save space
    WHERE
      updated_at < NOW() - INTERVAL '90 days'
      AND (usage_count < 3 OR usage_count IS NULL)
      AND NOT is_archived
      AND embedding IS NOT NULL
    RETURNING *
  )
  SELECT COUNT(*) INTO v_compressed_count FROM compressed;

  -- Log the operation
  INSERT INTO system_logs (operation, details)
  VALUES (
    'knowledge_archival',
    jsonb_build_object(
      'archived_count', v_archived_count,
      'compressed_count', v_compressed_count,
      'timestamp', NOW()
    )
  );

  RETURN QUERY SELECT v_archived_count, v_compressed_count;
END;
$$ LANGUAGE plpgsql;

-- Schedule monthly cleanup (using pg_cron extension)
SELECT cron.schedule(
  'monthly-knowledge-cleanup',
  '0 2 1 * *',  -- 2 AM on the 1st of every month
  $$ SELECT * FROM archive_old_knowledge(); $$
);

-- Manual cleanup function (for immediate execution)
CREATE OR REPLACE FUNCTION cleanup_knowledge_now()
RETURNS TEXT AS $$
DECLARE
  result RECORD;
BEGIN
  SELECT * INTO result FROM archive_old_knowledge();

  RETURN format(
    'Knowledge cleanup completed: %s items archived, %s items compressed',
    result.archived_count,
    result.compressed_count
  );
END;
$$ LANGUAGE plpgsql;

-- Usage:
-- SELECT cleanup_knowledge_now();
```

#### æ‰‹å‹•è§¸ç™¼æ¸…ç†

```typescript
// scripts/cleanup-knowledge.ts
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_KEY! // Use service key for admin operations
);

async function cleanupKnowledge() {
  console.log('ğŸ§¹ Starting knowledge cleanup...');

  const { data, error } = await supabase.rpc('cleanup_knowledge_now');

  if (error) {
    console.error('âŒ Cleanup failed:', error);
    process.exit(1);
  }

  console.log(`âœ… ${data}`);
}

cleanupKnowledge();
```

---

## ğŸ¯ Multi-LLM Router ç­–ç•¥

### å“è³ªå„ªå…ˆè·¯ç”±æ±ºç­–é‚è¼¯

```typescript
// services/llm-router.ts
function selectProvider(task: Task): Provider {
  const complexity = analyzeComplexity(task);
  const isSecurityTask = detectSecurityKeywords(task);
  const isUITask = detectUIKeywords(task);
  const messageLength = task.messages.reduce((sum, m) => sum + m.content.length, 0);

  // 1. High complexity or security-critical â†’ Claude 3.5 Sonnet (æœ€ä½³å“è³ª)
  if (complexity >= 8 || isSecurityTask) {
    return {
      provider: 'claude',
      model: 'claude-3-5-sonnet-20241022',
      reason: 'High complexity or security-critical task'
    };
  }

  // 2. UI/Frontend tasks â†’ GPT-4o-mini (è‰¯å¥½å‰ç«¯ç¶“é©—)
  if (isUITask) {
    return {
      provider: 'openai',
      model: 'gpt-4o-mini',
      reason: 'UI/Frontend task'
    };
  }

  // 3. Simple queries (<1000 chars) â†’ Gemini Pro (æˆæœ¬æ•ˆç›Š)
  if (messageLength < 1000) {
    return {
      provider: 'google',
      model: 'gemini-pro',
      reason: 'Simple query, cost-effective'
    };
  }

  // 4. Complex queries (>=1000 chars) â†’ GPT-4o-mini (å“è³ªä¿è­‰)
  return {
    provider: 'openai',
    model: 'gpt-4o-mini',
    reason: 'Complex query, balanced quality & cost'
  };
}

// Analyze task complexity (1-10)
function analyzeComplexity(task: Task): number {
  const content = task.messages.map(m => m.content).join(' ');
  let complexity = 5; // Base

  // Length-based
  if (content.length > 5000) complexity += 2;
  else if (content.length > 2000) complexity += 1;

  // High-complexity keywords
  const complexKeywords = [
    'architecture', 'system design', 'security', 'authentication',
    'scalability', 'distributed', 'microservices', 'database design',
    'performance optimization', 'algorithm', 'data structure'
  ];

  const matches = complexKeywords.filter(kw =>
    content.toLowerCase().includes(kw)
  );

  if (matches.length >= 3) complexity += 2;
  else if (matches.length >= 1) complexity += 1;

  return Math.min(complexity, 10);
}

// Detect security-related tasks
function detectSecurityKeywords(task: Task): boolean {
  const content = task.messages.map(m => m.content).join(' ').toLowerCase();

  const securityKeywords = [
    'security', 'auth', 'authentication', 'authorization',
    'rls', 'row level security', 'permission', 'access control',
    'encryption', 'jwt', 'token', 'api key', 'secret',
    'vulnerability', 'xss', 'csrf', 'sql injection', 'owasp'
  ];

  return securityKeywords.some(kw => content.includes(kw));
}

// Detect UI/Frontend tasks
function detectUIKeywords(task: Task): boolean {
  const content = task.messages.map(m => m.content).join(' ').toLowerCase();

  const uiKeywords = [
    'ui', 'user interface', 'frontend', 'component',
    'react', 'vue', 'svelte', 'css', 'tailwind',
    'styling', 'layout', 'responsive', 'design',
    'button', 'form', 'modal', 'dialog', 'navigation'
  ];

  return uiKeywords.some(kw => content.includes(kw));
}
```

### æˆæœ¬å„ªåŒ–çŸ©é™£ï¼ˆUpdatedï¼‰

| ä»»å‹™é¡å‹ | æ¨è–¦æ¨¡å‹ | æˆæœ¬/1K tokens | ä½¿ç”¨æ¯”ä¾‹ | æ¯æœˆæˆæœ¬ (10K requests) |
|---------|---------|---------------|----------|------------------------|
| **é«˜è¤‡é›œåº¦/å®‰å…¨** | Claude 3.5 Sonnet | $0.018 | 10% | $18 |
| **UI é–‹ç™¼** | GPT-4o-mini | $0.009 | 20% | $18 |
| **ä¸€èˆ¬é–‹ç™¼** | GPT-4o-mini | $0.009 | 20% | $18 |
| **ç°¡å–®æŸ¥è©¢** | Gemini Pro | $0.003 | 50% | $15 |
| **Embedding** | Gemini text-embedding-004 | **FREE** | - | $0 |
| **ç¸½è¨ˆ** | - | - | 100% | **~$69/æœˆ** |

*å‡è¨­æ¯è«‹æ±‚å¹³å‡ 1000 tokensï¼Œæ¯æœˆ 10,000 æ¬¡è«‹æ±‚*

### Fallback å®¹éŒ¯æ©Ÿåˆ¶ï¼ˆMulti-Levelï¼‰

```typescript
// Fallback Chain Configuration
const FALLBACK_CHAINS = {
  claude: ['gpt-4o', 'gpt-4o-mini', 'gemini-pro'],
  openai: ['claude-3-5-sonnet', 'gemini-pro'],
  google: ['gpt-4o-mini', 'claude-3-5-sonnet']
};

async function executeWithFallback(
  primaryProvider: Provider,
  task: Task,
  maxRetries: number = 2
): Promise<Response> {
  let lastError: Error | null = null;

  // Try primary provider
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const startTime = Date.now();
      const response = await primaryProvider.execute(task);
      const latency = Date.now() - startTime;

      // Log success
      await logAITrace({
        provider: primaryProvider.name,
        model: primaryProvider.model,
        task,
        response,
        latency,
        success: true
      });

      return response;
    } catch (error) {
      lastError = error as Error;
      console.error(
        `âŒ ${primaryProvider.name} attempt ${attempt + 1}/${maxRetries} failed:`,
        error
      );
    }
  }

  // Try fallback providers
  const fallbackProviders = FALLBACK_CHAINS[primaryProvider.name];

  for (const fallbackName of fallbackProviders) {
    const fallbackProvider = getProvider(fallbackName);

    console.log(`ğŸ”„ Falling back to ${fallbackName}...`);

    try {
      const response = await fallbackProvider.execute(task);

      // Log fallback success
      await logAITrace({
        provider: fallbackName,
        model: fallbackProvider.model,
        task,
        response,
        success: true,
        isFallback: true,
        primaryProvider: primaryProvider.name,
        primaryError: lastError?.message
      });

      return response;
    } catch (error) {
      console.error(`âŒ Fallback ${fallbackName} also failed:`, error);
    }
  }

  // All providers failed
  throw new Error(
    `All LLM providers failed. Primary: ${primaryProvider.name}, ` +
    `Fallbacks: ${fallbackProviders.join(', ')}. ` +
    `Last error: ${lastError?.message}`
  );
}
```

---

## ğŸ“¦ Phase äº¤ä»˜æµç¨‹ï¼ˆPhase Delivery Workflowï¼‰

### Phase 1: çŸ¥è­˜å¾ªç’°åŸºç¤æ¶æ§‹ï¼ˆKnowledge Circulation Infrastructureï¼‰

**Timeline**: 3-4 days | **Quality Gate**: >= 85/100

#### Deliverables

1. **Supabase Vector DB å¯¦ä½œ** âœ…
   - Schema creation (knowledge_base table)
   - Vector indexes (ivfflat with 768 dimensions)
   - Full-text search functions | Hybrid search (text + vector)
   - RLS policies (security levels)

2. **DevJournalLogger å¯¦ä½œ** âœ…
   - Automatic knowledge capture | Markdown backup to local filesystem
   - Gemini embedding generation | Summary generation | Metadata extraction

3. **RAG Engine å¯¦ä½œ** âœ…
   - Semantic search (hybrid approach) | Prompt enhancement with context
   - Security-level filtering | Top-K retrieval with re-ranking | Source attribution

4. **AgentTrainingSystem å¯¦ä½œ** âœ…
   - Before-task knowledge retrieval | After-task learning logging
   - Usage statistics tracking | Learning curve metrics | Quality feedback loop

5. **Documentation** âœ…
   - API documentation (JSDoc) | Integration guide | Testing guide | Quality verification report

#### Testing Requirements

```yaml
Unit Tests:
  DevJournalLogger: 10 tests | RAG Engine: 12 tests | AgentTrainingSystem: 8 tests
  Coverage: >= 80%

Integration Tests:
  End-to-end knowledge flow: 5 tests | Vector search accuracy: 3 tests | Supabase integration: 4 tests
  Coverage: >= 75%

Performance Tests:
  Vector search latency: < 100ms (P95) | Embedding generation: < 2s per document | Knowledge retrieval: < 200ms (P95)
```

### Phase 2 & 3: obs-edge API å±¤ & obs-dashboard å‰ç«¯

è«‹åƒè€ƒ **[PHASE_DELIVERY_PLAN.md](./PHASE_DELIVERY_PLAN.md)** å–å¾—å®Œæ•´çš„ Phase 2-3 äº¤ä»˜è¨ˆç•«ã€‚

---

## ğŸ›¡ï¸ æŠ€è¡“å‚µå‹™é é˜²ç­–ç•¥ï¼ˆTechnical Debt Preventionï¼‰

### å–®ä¸€çœŸå¯¦ä¾†æºåŸå‰‡ï¼ˆSingle Source of Truthï¼‰

**Before Creating New Files:**

```typescript
// âŒ WRONG: Creating duplicate implementations
// file: services/user-manager-v2.ts
export class UserManagerV2 { async getUser(id: string) { /* ... */ } }

// âœ… CORRECT: Extending existing implementation
// file: services/user-manager.ts
export class UserManager {
  async getUser(id: string) { /* existing code */ }
  async getUserWithCache(id: string) { /* new functionality */ }
}
```

### ä»£ç¢¼é‡ç”¨æª¢æŸ¥æ¸…å–®ï¼ˆCode Reuse Checklistï¼‰

**Before implementing any feature:**

1. â˜‘ï¸ **Search First** - `Grep(pattern="class.*Manager", glob="**/*.ts")`
2. â˜‘ï¸ **Analyze Existing** - `Read(file_path="services/existing-manager.ts")`
3. â˜‘ï¸ **Decision Tree**: Can extend existing? â†’ **DO IT** | Must create new? â†’ **Document why**
4. â˜‘ï¸ **Follow Patterns** - Same error handling, logging, naming conventions

### å®šæœŸæŠ€è¡“å‚µå‹™æ¸…ç†ï¼ˆRegular Debt Cleanupï¼‰

**Quarterly Tech Debt Sprint:**

```yaml
Q1 Cleanup (March): Consolidate duplicate utilities | Remove unused dependencies | Update outdated packages
Q2 Cleanup (June): Database query optimization | API response time improvements | Remove deprecated code
Q3 Cleanup (September): Security audit (Snyk/CodeQL) | Performance profiling | Test coverage gaps
Q4 Cleanup (December): Year-end architecture review | Dependency major version upgrades | Prepare for next year roadmap
```

---

## ğŸ” å®‰å…¨èˆ‡åˆè¦ï¼ˆSecurity & Complianceï¼‰

### èªè­‰èˆ‡æˆæ¬Šï¼ˆAuthentication & Authorization)

**JWT Token Management:**

```typescript
// services/auth.ts
import { SignJWT, jwtVerify } from 'jose';

export async function generateToken(user: User): Promise<string> {
  const secret = new TextEncoder().encode(process.env.JWT_SECRET);
  return await new SignJWT({ sub: user.id, email: user.email, role: user.role })
    .setProtectedHeader({ alg: 'HS256' })
    .setIssuedAt()
    .setExpirationTime('1h') // Short-lived access token
    .sign(secret);
}

export async function generateRefreshToken(user: User): Promise<string> {
  const secret = new TextEncoder().encode(process.env.REFRESH_SECRET);
  return await new SignJWT({ sub: user.id })
    .setProtectedHeader({ alg: 'HS256' })
    .setIssuedAt()
    .setExpirationTime('7d') // Long-lived refresh token
    .sign(secret);
}

export async function verifyToken(token: string): Promise<JWTPayload> {
  const secret = new TextEncoder().encode(process.env.JWT_SECRET);
  const { payload } = await jwtVerify(token, secret);
  return payload;
}
```

**Row Level Security (RLS) Policies:**

```sql
-- Only users can see their own data
CREATE POLICY "Users can view own data" ON user_data FOR SELECT USING (auth.uid() = user_id);

-- Only admins can view all data
CREATE POLICY "Admins can view all data" ON user_data FOR SELECT USING (auth.jwt() ->> 'role' = 'admin');

-- Users can insert their own data
CREATE POLICY "Users can insert own data" ON user_data FOR INSERT WITH CHECK (auth.uid() = user_id);

-- Prevent users from updating other users' data
CREATE POLICY "Users can only update own data" ON user_data FOR UPDATE USING (auth.uid() = user_id);
```

### API Key è¼ªæ›æ©Ÿåˆ¶ï¼ˆAPI Key Rotationï¼‰

```typescript
// services/api-key-manager.ts
export class APIKeyManager {
  // Generate new API key
  async generateKey(userId: string, name: string): Promise<string> {
    const key = `gf_${randomBytes(32).toString('hex')}`;
    const hashedKey = await this.hashKey(key);
    await this.supabase.from('api_keys').insert({
      user_id: userId, name, key_hash: hashedKey,
      created_at: new Date().toISOString(),
      expires_at: new Date(Date.now() + 90 * 24 * 60 * 60 * 1000).toISOString() // 90 days
    });
    return key; // Return plaintext key ONCE
  }

  // Rotate existing key (generate new, deprecate old)
  async rotateKey(oldKeyId: string): Promise<string> {
    const { data: oldKey } = await this.supabase.from('api_keys').select('user_id, name').eq('id', oldKeyId).single();
    if (!oldKey) throw new Error('Key not found');

    const newKey = await this.generateKey(oldKey.user_id, oldKey.name);

    // Mark old key as deprecated (grace period: 7 days)
    await this.supabase.from('api_keys').update({
      deprecated_at: new Date().toISOString(),
      expires_at: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000).toISOString()
    }).eq('id', oldKeyId);

    return newKey;
  }

  // Verify API key
  async verifyKey(key: string): Promise<{ valid: boolean; userId: string | null }> {
    const hashedKey = await this.hashKey(key);
    const { data } = await this.supabase.from('api_keys').select('user_id, expires_at').eq('key_hash', hashedKey).single();
    if (!data || new Date() > new Date(data.expires_at)) return { valid: false, userId: null };
    await this.supabase.from('api_keys').update({ last_used_at: new Date().toISOString() }).eq('key_hash', hashedKey);
    return { valid: true, userId: data.user_id };
  }

  private async hashKey(key: string): Promise<string> {
    return createHash('sha256').update(key).digest('hex');
  }
}
```

### è¼¸å…¥é©—è­‰èˆ‡æ¸…ç†ï¼ˆInput Validation & Sanitizationï¼‰

```typescript
// Use Zod schemas for all API inputs
import { z } from 'zod';

export const createMetricSchema = z.object({
  name: z.string().min(1).max(100),
  value: z.number().min(0),
  timestamp: z.date(),
  tags: z.array(z.string()).optional(),
  metadata: z.record(z.string(), z.unknown()).optional()
});

// Use in tRPC router
export const metricsRouter = router({
  create: procedure
    .input(createMetricSchema) // Automatic validation
    .mutation(async ({ input, ctx }) => {
      const metric = await ctx.db.insert(metrics).values(input);
      return metric;
    })
});
```

### å¯©è¨ˆæ—¥èªŒï¼ˆAudit Loggingï¼‰

```typescript
// services/audit-logger.ts
interface AuditLog {
  timestamp: string; user_id: string; action: string;
  resource_type: string; resource_id: string;
  details: Record<string, unknown>; ip_address: string; user_agent: string;
}

export async function logAudit(log: AuditLog): Promise<void> {
  await supabase.from('audit_logs').insert({ ...log, timestamp: new Date().toISOString() });
  if (process.env.NODE_ENV === 'production') await sendToCloudWatch(log); // External logging
}
```

---

## ğŸ› ï¸ é–‹ç™¼å·¥å…·èˆ‡æŒ‡ä»¤ï¼ˆDevelopment Tools & Commandsï¼‰

### æœ¬åœ°é–‹ç™¼ï¼ˆLocal Developmentï¼‰

```bash
# Frontend (obs-dashboard)
cd apps/obs-dashboard && pnpm dev  # http://localhost:3000

# Backend (obs-edge)
cd apps/obs-edge && wrangler dev   # http://localhost:8787

# Full Stack
pnpm dev                           # Start all services concurrently

# Database
wrangler d1 execute DB --local --file=schema.sql  # Run migrations locally
pnpm db:studio                     # Open Drizzle Studio
```

### æ¸¬è©¦ï¼ˆTestingï¼‰

```bash
# Unit Tests
pnpm test                          # Run all unit tests (Vitest)
pnpm test:coverage                 # Generate coverage report
pnpm test:watch                    # Watch mode

# E2E Tests
pnpm test:e2e                      # Run Playwright tests
pnpm test:e2e:ui                   # Run with UI mode (interactive)
pnpm test:e2e:debug                # Debug mode

# Load Tests
pnpm test:load                     # Run k6 load tests
pnpm test:stress                   # Stress testing (high concurrency)
```

### éƒ¨ç½²ï¼ˆDeploymentï¼‰

```bash
# Preview Deployment (PR)
pnpm deploy:preview                # Deploy to Cloudflare Pages preview

# Production Deployment
pnpm deploy:production             # Deploy to production
pnpm deploy:obs-edge               # Deploy Workers only
pnpm deploy:obs-dashboard          # Deploy Pages only

# Rollback
wrangler rollback <version>        # Rollback Workers
```

### è³‡æ–™åº«ç®¡ç†ï¼ˆDatabase Managementï¼‰

```bash
# Migrations
pnpm db:generate                   # Generate migration files
pnpm db:migrate                    # Apply migrations
pnpm db:push                       # Push schema changes (dev only)
pnpm db:studio                     # Open Drizzle Studio

# Supabase
supabase start                     # Start local Supabase
supabase db reset                  # Reset database
supabase functions deploy          # Deploy Edge Functions
```

### ç›£æ§èˆ‡é™¤éŒ¯ï¼ˆMonitoring & Debuggingï¼‰

```bash
# Logs
wrangler tail                      # Tail Cloudflare Workers logs
wrangler tail --format json        # JSON format logs

# Metrics
curl https://obs-edge.example.com/health   # Health check
curl https://obs-edge.example.com/metrics  # Prometheus metrics

# Debug
NODE_OPTIONS='--inspect' pnpm dev  # Node.js debugger
pnpm dev --turbo --debug           # Turbopack debug mode
```

---

## ğŸ“š åƒè€ƒæ–‡æª”ï¼ˆReference Documentationï¼‰

### å…§éƒ¨æ–‡æª”ï¼ˆInternal Docsï¼‰

- **[SYSTEM_ARCHITECTURE.md](./SYSTEM_ARCHITECTURE.md)** - Complete architecture diagrams (11 Mermaid diagrams)
- **[PHASE_DELIVERY_PLAN.md](./PHASE_DELIVERY_PLAN.md)** - 4-phase delivery plan with timelines
- **[QUALITY_REPORT_TEMPLATE.md](./QUALITY_REPORT_TEMPLATE.md)** - Quality verification template
- **[PHASE_0_QUALITY_REPORT.md](./PHASE_0_QUALITY_REPORT.md)** - Phase 0 quality report (91/100)

### å¤–éƒ¨æ–‡æª”ï¼ˆExternal Docsï¼‰

**Cloudflare:** [Workers](https://developers.cloudflare.com/workers/) | [Durable Objects](https://developers.cloudflare.com/workers/runtime-apis/durable-objects/) | [D1 Database](https://developers.cloudflare.com/d1/) | [R2 Storage](https://developers.cloudflare.com/r2/) | [Vectorize](https://developers.cloudflare.com/vectorize/)

**Supabase:** [PostgreSQL + pgvector](https://supabase.com/docs/guides/database/extensions/pgvector) | [Row Level Security](https://supabase.com/docs/guides/auth/row-level-security) | [Realtime](https://supabase.com/docs/guides/realtime)

**LLM Providers:** [Claude 3.5 Sonnet](https://docs.anthropic.com/claude/docs/models-overview#claude-3-5-sonnet) | [GPT-4o-mini](https://platform.openai.com/docs/models/gpt-4o-mini) | [Gemini Pro](https://ai.google.dev/gemini-api/docs/models/gemini)

**Testing:** [Vitest](https://vitest.dev/) | [Playwright](https://playwright.dev/) | [k6 Load Testing](https://k6.io/docs/)

**DevOps:** [GitHub Actions](https://docs.github.com/en/actions) | [Snyk Security](https://docs.snyk.io/) | [OpenTelemetry](https://opentelemetry.io/docs/)

---

## ğŸ“ æœ€ä½³å¯¦è¸ç¸½çµï¼ˆBest Practices Summaryï¼‰

### ä»£ç¢¼å“è³ªï¼ˆCode Quality)
1. **TypeScript Strict Mode** - 100% type safety, no `any` types
2. **Single Source of Truth** - One authoritative implementation per feature
3. **DRY Principle** - Don't Repeat Yourself, extract shared logic
4. **SOLID Principles** - Especially Single Responsibility and Dependency Inversion
5. **Code Reviews** - Dual review requirement (2+ approvals)

### æ¸¬è©¦ç­–ç•¥ï¼ˆTesting Strategyï¼‰
1. **Test Pyramid** - More unit tests, fewer E2E tests
2. **Test Coverage** - >= 80% statement coverage
3. **TDD Encouraged** - Write tests before or with implementation
4. **E2E Critical Flows** - Cover all critical user paths
5. **Performance Tests** - Regular load testing before releases

### å®‰å…¨æ€§ï¼ˆSecurityï¼‰
1. **Defense in Depth** - Multiple layers of security
2. **Least Privilege** - Grant minimum necessary permissions
3. **Input Validation** - Validate all inputs with Zod schemas
4. **Audit Logging** - Log all critical operations
5. **Regular Audits** - Quarterly security audits

### æ€§èƒ½å„ªåŒ–ï¼ˆPerformanceï¼‰
1. **Edge Computing** - Use Cloudflare Workers for low latency
2. **Caching Strategy** - KV for hot data, R2 for cold data
3. **Database Optimization** - Proper indexes, query optimization
4. **CDN Usage** - Static assets via Cloudflare Pages
5. **Monitoring** - OpenTelemetry + Prometheus + Grafana

### æ–‡æª”ç¶­è­·ï¼ˆDocumentationï¼‰
1. **Always Up-to-Date** - Update docs with code changes
2. **Code Comments** - JSDoc for all public functions
3. **Architecture Decisions** - Document ADRs for major decisions
4. **API Documentation** - OpenAPI/Swagger specs
5. **Runbooks** - Operational procedures for incidents

---

## âœ… Phase å®Œæˆæª¢æŸ¥æ¸…å–®ï¼ˆPhase Completion Checklistï¼‰

**åœ¨æ¨™è¨˜ Phase å®Œæˆå‰ï¼Œç¢ºèªä»¥ä¸‹æ‰€æœ‰é …ç›®ï¼š**

### åŠŸèƒ½å®Œæ•´æ€§ï¼ˆFunctionalityï¼‰
- [ ] All deliverables 100% complete
- [ ] All features working as specified
- [ ] No critical bugs or blockers
- [ ] Edge cases handled

### æ¸¬è©¦è¦†è“‹ç‡ï¼ˆTestingï¼‰
- [ ] Unit tests >= 80% coverage
- [ ] Integration tests passing
- [ ] E2E tests for critical flows
- [ ] Performance tests meet SLA

### ä»£ç¢¼å“è³ªï¼ˆCode Qualityï¼‰
- [ ] ESLint: 0 errors, 0 warnings
- [ ] TypeScript: 0 type errors, 100% strict
- [ ] Code review: 2+ approvals
- [ ] No code duplication

### æ€§èƒ½æŒ‡æ¨™ï¼ˆPerformanceï¼‰
- [ ] P95 latency < SLA target
- [ ] Load test passing (expected load)
- [ ] No memory leaks
- [ ] Database queries optimized

### å®‰å…¨æ€§ï¼ˆSecurityï¼‰
- [ ] 0 critical vulnerabilities
- [ ] 0 high vulnerabilities
- [ ] API keys in environment variables
- [ ] Input validation implemented
- [ ] RLS policies enabled

### æ–‡æª”å®Œæ•´åº¦ï¼ˆDocumentationï¼‰
- [ ] README updated
- [ ] API docs complete (>= 90%)
- [ ] JSDoc for all public functions
- [ ] Architecture diagrams updated
- [ ] CHANGELOG updated

### éƒ¨ç½²å°±ç·’ï¼ˆDeploymentï¼‰
- [ ] CI/CD pipeline passing (all 6 gates)
- [ ] Preview deployment working
- [ ] Production deployment tested
- [ ] Rollback plan documented
- [ ] Monitoring alerts configured

### å“è³ªåˆ†æ•¸ï¼ˆQuality Scoreï¼‰
- [ ] **Total Score >= 85/100**
- [ ] Individual categories >= 75/100
- [ ] No failing tests
- [ ] No critical issues

---

## ğŸ¯ è¯çµ¡èˆ‡æ”¯æ´ï¼ˆContact & Supportï¼‰

**Project Lead**: Morris Lin
**Repository**: https://github.com/your-org/genesis-observability
**Documentation**: https://docs.genesis-observability.com

**Support Channels:**
- GitHub Issues: Bug reports and feature requests
- Discussions: General questions and community support
- Email: support@genesis-observability.com (production issues)

---

**ğŸ“ Document Version**: 2.0 (Enterprise Grade)
**ğŸ”„ Last Updated**: 2025-01-07
**âœ… Status**: Phase 0 Complete (91/100) | Phase 1 In Planning
**ğŸ¯ Next Milestone**: Phase 1 - Knowledge Circulation Infrastructure (3-4 days)

---

## âš ï¸ IMPORTANT REMINDER

**Before starting ANY task, Claude Code MUST:**

1. âœ… **Acknowledge all critical rules** in CLAUDE.md
2. ğŸ” **Complete the mandatory pre-task compliance check** (all 4 steps)
3. ğŸš« **Verify no prohibitions are violated**
4. âœ… **Ensure all mandatory requirements are followed**
5. ğŸ“ **Use TodoWrite for complex tasks** (3+ steps)
6. ğŸ”„ **Commit and push to GitHub after each completed task**

**These rules ensure consistency, professionalism, highest quality, and commercial viability.**

---
